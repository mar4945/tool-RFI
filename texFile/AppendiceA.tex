\lhead{\bfseries Appendix}
	\appendix
	\chapter{Optimization and Optimal Control}
	\label{app:optimalControl}
	
	\section{Model Predictive Control}
\subsection*{Introduction}
Model Predictive Control (MPC) is a sophisticated control strategy used extensively in industrial processes and advanced engineering systems. Unlike traditional control methods, MPC employs a model of the system to predict future behavior and optimize performance over a specified time horizon. This approach allows for the handling of multivariable control problems and the accommodation of constraints on inputs and outputs, making it particularly powerful for complex applications.



\subsection*{Fundamental Principles}
At the core of MPC is the use of a dynamic model to forecast future system behavior. This model, typically derived from physical principles or system identification techniques, allows the controller to predict the future states of the system over a specified horizon. The control action is then determined by solving an optimization problem that minimizes a cost function subject to the system constraints.

The optimization problem in MPC can be formulated as follows:
\[
\min_{u_{0}, u_{1}, \ldots, u_{N-1}} \sum_{k=0}^{N-1} \left( x_k^T Q x_k + u_k^T R u_k \right) + x_N^T P x_N
\]
subject to:
\[
x_{k+1} = f(x_k, u_k), \quad k = 0, 1, \ldots, N-1
\]
\[
x_k \in \mathcal{X}, \; u_k \in \mathcal{U}, \quad k = 0, 1, \ldots, N-1
\]
where:
\begin{itemize}
	\item \(x_k\) is the state vector at time step \(k\),
	\item \(u_k\) is the control input vector at time step \(k\),
	\item \(Q\), \(R\), and \(P\) are positive semi-definite weighting matrices,
	\item \(f\) is the system model,
	\item \(\mathcal{X}\) and \(\mathcal{U}\) are the sets of allowable states and inputs, respectively,
	\item \(N\) is the prediction horizon.
\end{itemize}

\subsection*{State Space Model}
The system model \(f\) is often represented in a state-space form, particularly for linear systems:
\[
x_{k+1} = A x_k + B u_k + w_k
\]
\[
y_k = C x_k + D u_k + v_k
\]
where:
\begin{itemize}
	\item \(A\), \(B\), \(C\), and \(D\) are matrices defining the system dynamics,
	\item \(w_k\) and \(v_k\) represent process and measurement noise, respectively,
	\item \(y_k\) is the output vector.
\end{itemize}

For nonlinear systems, the state-space model takes a more general form:
\[
x_{k+1} = f(x_k, u_k) + w_k
\]
\[
y_k = h(x_k, u_k) + v_k
\]
where \(f\) and \(h\) are nonlinear functions that describe the system dynamics and output, respectively.

\subsection*{Constraints}
MPC explicitly handles constraints on states and inputs, which can be critical for ensuring safe and feasible operation. These constraints can be expressed as:
\[
x_k \in \mathcal{X} = \{x \in \mathbb{R}^n \mid g_x(x) \leq 0\}
\]
\[
u_k \in \mathcal{U} = \{u \in \mathbb{R}^m \mid g_u(u) \leq 0\}
\]
where \(g_x\) and \(g_u\) are constraint functions that define the allowable regions for states and inputs.

\subsection*{Cost Function}
The cost function in MPC typically includes terms for both state deviation and control effort:
\[
J = \sum_{k=0}^{N-1} \left( x_k^T Q x_k + u_k^T R u_k \right) + x_N^T P x_N
\]
\begin{itemize}
	\item The term \(x_k^T Q x_k\) penalizes deviations of the state from the desired trajectory.
	\item The term \(u_k^T R u_k\) penalizes the use of control inputs.
	\item The terminal cost \(x_N^T P x_N\) ensures stability and performance over the prediction horizon.
\end{itemize}

\subsection*{Optimization Problem}
The optimization problem solved at each time step in MPC can be summarized as:
\[
\begin{aligned}
	\min_{u_{0}, u_{1}, \ldots, u_{N-1}} & \quad \sum_{k=0}^{N-1} \left( x_k^T Q x_k + u_k^T R u_k \right) + x_N^T P x_N \\
	\text{subject to} & \quad x_{k+1} = f(x_k, u_k), \quad k = 0, 1, \ldots, N-1 \\
	& \quad x_k \in \mathcal{X}, \; u_k \in \mathcal{U}, \quad k = 0, 1, \ldots, N-1 \\
	& \quad x_0 = x(t)
\end{aligned}
\]
where \(x(t)\) is the current state of the system.

The solution to this optimization problem yields a sequence of control actions \(u_0, u_1, \ldots, u_{N-1}\). However, only the first control action \(u_0\) is implemented. The optimization is then repeated at the next time step with updated state measurements, following the receding horizon strategy.

\subsection*{Nonlinear Model Predictive Control (NMPC)}
For systems with nonlinear dynamics, the optimization problem becomes more complex due to the nonlinear functions \(f\) and \(h\). The cost function and constraints must be adapted to handle these nonlinearities.

The NMPC problem can be formulated as:
\[
\begin{aligned}
	\min_{u_{0}, u_{1}, \ldots, u_{N-1}} & \quad \sum_{k=0}^{N-1} \left( l(x_k, u_k) \right) + l_f(x_N) \\
	\text{subject to} & \quad x_{k+1} = f(x_k, u_k), \quad k = 0, 1, \ldots, N-1 \\
	& \quad y_k = h(x_k, u_k), \quad k = 0, 1, \ldots, N-1 \\
	& \quad x_k \in \mathcal{X}, \; u_k \in \mathcal{U}, \quad k = 0, 1, \ldots, N-1 \\
	& \quad x_0 = x(t)
\end{aligned}
\]
where \(l\) and \(l_f\) are the running cost and terminal cost functions, respectively.

\subsection*{Solving NMPC Problems}
The nonlinear nature of NMPC problems requires specialized numerical techniques for their solution. Common methods include:
\begin{enumerate}
	\item \textbf{Sequential Quadratic Programming (SQP)}: This method approximates the nonlinear problem by a sequence of quadratic programming subproblems, which are easier to solve.
	\item \textbf{Interior Point Methods}: These methods handle constraints by incorporating them into the objective function through barrier functions, which are then optimized iteratively.
	\item \textbf{Direct Methods}: These methods discretize the control problem directly, transforming it into a large-scale nonlinear programming problem. Examples include direct collocation and multiple shooting.
\end{enumerate}

NMPC builds on the strengths of linear MPC by effectively managing multivariable systems and constraints. Moreover, NMPC excels in handling systems with strong nonlinearities, offering precise and effective control where linear approximations fall short.

NMPC is extensively utilized in industries characterized by nonlinear behaviors, such as chemical process control, aerospace, automotive systems, and robotics. For instance, NMPC optimizes control in chemical reactors with highly nonlinear reaction kinetics and in autonomous vehicles with complex, varying dynamics. In aerospace, NMPC enhances flight control systems, while in robotics, it facilitates precise maneuvering in dynamic environments.

However, NMPC faces significant challenges, particularly in computational complexity and the need for precise models. Real-time nonlinear optimization demands substantial computational resources, and model inaccuracies can degrade performance. Addressing these issues requires robust algorithms capable of real-time execution. Future research is directed towards enhancing computational efficiency through advanced algorithms and leveraging machine learning for more accurate models. Integrating NMPC with artificial intelligence and real-time optimization techniques shows promise for expanding its applicability in increasingly complex environments. Innovations in hardware, such as parallel processing and dedicated optimization chips, offer potential solutions to current computational limitations.

Model Predictive Control, including its nonlinear variant, represents a significant advancement in control theory, providing powerful tools for managing complex, multivariable systems with constraints. The ability to predict future behavior and optimize performance in real-time makes MPC and NMPC invaluable across various industries. As computational capabilities advance and new techniques emerge, the effectiveness and scope of MPC are poised to grow, cementing its role as a cornerstone of modern control engineering. NMPC's proficiency in handling nonlinearities and real-time optimization underscores its continued relevance in advancing industrial automation and control systems.